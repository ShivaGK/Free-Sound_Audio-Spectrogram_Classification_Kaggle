{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from collections import Counter, defaultdict\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from psutil import cpu_count\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 9999\n",
    "seed_everything(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = cpu_count()\n",
    "os.environ['MKL_NUM_THREADS'] = str(N_JOBS)\n",
    "os.environ['OMP_NUM_THREADS'] = str(N_JOBS)\n",
    "DataLoader = partial(DataLoader, num_workers=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from official code https://colab.research.google.com/drive/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8#scrollTo=cRCaCIb9oguU\n",
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "    \"\"\"Calculate precisions for each true class for a single sample.\n",
    "\n",
    "    Args:\n",
    "      scores: np.array of (num_classes,) giving the individual classifier scores.\n",
    "      truth: np.array of (num_classes,) bools indicating which classes are true.\n",
    "\n",
    "    Returns:\n",
    "      pos_class_indices: np.array of indices of the true classes for this sample.\n",
    "      pos_class_precisions: np.array of precisions corresponding to each of those\n",
    "        classes.\n",
    "    \"\"\"\n",
    "    num_classes = scores.shape[0]\n",
    "    pos_class_indices = np.flatnonzero(truth > 0)\n",
    "    # Only calculate precisions if there are some true classes.\n",
    "    if not len(pos_class_indices):\n",
    "        return pos_class_indices, np.zeros(0)\n",
    "    # Retrieval list of classes for this sample.\n",
    "    retrieved_classes = np.argsort(scores)[::-1]\n",
    "    # class_rankings[top_scoring_class_index] == 0 etc.\n",
    "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "    class_rankings[retrieved_classes] = range(num_classes)\n",
    "    # Which of these is a true label?\n",
    "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "    # Num hits for every truncated retrieval list.\n",
    "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
    "    precision_at_hits = (\n",
    "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
    "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "    return pos_class_indices, precision_at_hits\n",
    "\n",
    "\n",
    "def calculate_per_class_lwlrap(truth, scores):\n",
    "    \"\"\"Calculate label-weighted label-ranking average precision.\n",
    "\n",
    "    Arguments:\n",
    "      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
    "        of presence of that class in that sample.\n",
    "      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
    "        test's real-valued score for each class for each sample.\n",
    "\n",
    "    Returns:\n",
    "      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n",
    "        class.\n",
    "      weight_per_class: np.array of (num_classes,) giving the prior of each\n",
    "        class within the truth labels.  Then the overall unbalanced lwlrap is\n",
    "        simply np.sum(per_class_lwlrap * weight_per_class)\n",
    "    \"\"\"\n",
    "    assert truth.shape == scores.shape\n",
    "    num_samples, num_classes = scores.shape\n",
    "    # Space to store a distinct precision value for each class on each sample.\n",
    "    # Only the classes that are true for each sample will be filled in.\n",
    "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "    for sample_num in range(num_samples):\n",
    "        pos_class_indices, precision_at_hits = (\n",
    "            _one_sample_positive_class_precisions(scores[sample_num, :],\n",
    "                                                  truth[sample_num, :]))\n",
    "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
    "            precision_at_hits)\n",
    "    labels_per_class = np.sum(truth > 0, axis=0)\n",
    "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "    # Form average of each column, i.e. all the precisions assigned to labels in\n",
    "    # a particular class.\n",
    "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
    "                        np.maximum(1, labels_per_class))\n",
    "    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
    "    #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
    "    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
    "    #                = np.sum(per_class_lwlrap * weight_per_class)\n",
    "    return per_class_lwlrap, weight_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "dataset_dir = Path('../input/freesound-audio-tagging-2019')\n",
    "preprocessed_dir = Path('../input/fat2019_prep_mels1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = {\n",
    "    'train_curated': dataset_dir / 'train_curated.csv',\n",
    "    #'train_noisy': dataset_dir / 'train_noisy.csv',\n",
    "    'train_noisy': preprocessed_dir / 'trn_noisy_best50s.csv',\n",
    "    'sample_submission': dataset_dir / 'sample_submission.csv',\n",
    "}\n",
    "\n",
    "dataset = {\n",
    "    'train_curated': dataset_dir / 'train_curated',\n",
    "    'train_noisy': dataset_dir / 'train_noisy',\n",
    "    'test': dataset_dir / 'test',\n",
    "}\n",
    "\n",
    "mels = {\n",
    "    'train_curated': preprocessed_dir / 'mels_train_curated.pkl',\n",
    "    'train_noisy': preprocessed_dir / 'mels_trn_noisy_best50s.pkl',\n",
    "    'test': preprocessed_dir / 'mels_test.pkl',  # NOTE: this data doesn't work at 2nd stage\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "      <th>singled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006ae4e.wav</td>\n",
       "      <td>Bark</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0019ef41.wav</td>\n",
       "      <td>Raindrop</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ec0ad.wav</td>\n",
       "      <td>Finger_snapping</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0026c7cb.wav</td>\n",
       "      <td>Run</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0026f116.wav</td>\n",
       "      <td>Finger_snapping</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname           labels singled\n",
       "0  0006ae4e.wav             Bark     NaN\n",
       "1  0019ef41.wav         Raindrop     NaN\n",
       "2  001ec0ad.wav  Finger_snapping     NaN\n",
       "3  0026c7cb.wav              Run     NaN\n",
       "4  0026f116.wav  Finger_snapping     NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_curated = pd.read_csv(csvs['train_curated'])\n",
    "train_noisy = pd.read_csv(csvs['train_noisy'])\n",
    "train_df = pd.concat([train_curated, train_noisy], sort=True, ignore_index=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>Accelerating_and_revving_and_vroom</th>\n",
       "      <th>Accordion</th>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <th>Applause</th>\n",
       "      <th>Bark</th>\n",
       "      <th>Bass_drum</th>\n",
       "      <th>Bass_guitar</th>\n",
       "      <th>Bathtub_(filling_or_washing)</th>\n",
       "      <th>Bicycle_bell</th>\n",
       "      <th>Burping_and_eructation</th>\n",
       "      <th>Bus</th>\n",
       "      <th>Buzz</th>\n",
       "      <th>Car_passing_by</th>\n",
       "      <th>Cheering</th>\n",
       "      <th>Chewing_and_mastication</th>\n",
       "      <th>Child_speech_and_kid_speaking</th>\n",
       "      <th>Chink_and_clink</th>\n",
       "      <th>Chirp_and_tweet</th>\n",
       "      <th>Church_bell</th>\n",
       "      <th>Clapping</th>\n",
       "      <th>Computer_keyboard</th>\n",
       "      <th>Crackle</th>\n",
       "      <th>Cricket</th>\n",
       "      <th>Crowd</th>\n",
       "      <th>Cupboard_open_or_close</th>\n",
       "      <th>Cutlery_and_silverware</th>\n",
       "      <th>Dishes_and_pots_and_pans</th>\n",
       "      <th>Drawer_open_or_close</th>\n",
       "      <th>Drip</th>\n",
       "      <th>Electric_guitar</th>\n",
       "      <th>Fart</th>\n",
       "      <th>Female_singing</th>\n",
       "      <th>Female_speech_and_woman_speaking</th>\n",
       "      <th>Fill_(with_liquid)</th>\n",
       "      <th>Finger_snapping</th>\n",
       "      <th>Frying_(food)</th>\n",
       "      <th>Gasp</th>\n",
       "      <th>Glockenspiel</th>\n",
       "      <th>Gong</th>\n",
       "      <th>...</th>\n",
       "      <th>Harmonica</th>\n",
       "      <th>Hi-hat</th>\n",
       "      <th>Hiss</th>\n",
       "      <th>Keys_jangling</th>\n",
       "      <th>Knock</th>\n",
       "      <th>Male_singing</th>\n",
       "      <th>Male_speech_and_man_speaking</th>\n",
       "      <th>Marimba_and_xylophone</th>\n",
       "      <th>Mechanical_fan</th>\n",
       "      <th>Meow</th>\n",
       "      <th>Microwave_oven</th>\n",
       "      <th>Motorcycle</th>\n",
       "      <th>Printer</th>\n",
       "      <th>Purr</th>\n",
       "      <th>Race_car_and_auto_racing</th>\n",
       "      <th>Raindrop</th>\n",
       "      <th>Run</th>\n",
       "      <th>Scissors</th>\n",
       "      <th>Screaming</th>\n",
       "      <th>Shatter</th>\n",
       "      <th>Sigh</th>\n",
       "      <th>Sink_(filling_or_washing)</th>\n",
       "      <th>Skateboard</th>\n",
       "      <th>Slam</th>\n",
       "      <th>Sneeze</th>\n",
       "      <th>Squeak</th>\n",
       "      <th>Stream</th>\n",
       "      <th>Strum</th>\n",
       "      <th>Tap</th>\n",
       "      <th>Tick-tock</th>\n",
       "      <th>Toilet_flush</th>\n",
       "      <th>Traffic_noise_and_roadway_noise</th>\n",
       "      <th>Trickle_and_dribble</th>\n",
       "      <th>Walk_and_footsteps</th>\n",
       "      <th>Water_tap_and_faucet</th>\n",
       "      <th>Waves_and_surf</th>\n",
       "      <th>Whispering</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Yell</th>\n",
       "      <th>Zipper_(clothing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000ccb97.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0012633b.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ed5f1.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00294be0.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003fde7a.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname        ...          Zipper_(clothing)\n",
       "0  000ccb97.wav        ...                          0\n",
       "1  0012633b.wav        ...                          0\n",
       "2  001ed5f1.wav        ...                          0\n",
       "3  00294be0.wav        ...                          0\n",
       "4  003fde7a.wav        ...                          0\n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(csvs['sample_submission'])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accelerating_and_revving_and_vroom',\n",
       " 'Accordion',\n",
       " 'Acoustic_guitar',\n",
       " 'Applause',\n",
       " 'Bark',\n",
       " 'Bass_drum',\n",
       " 'Bass_guitar',\n",
       " 'Bathtub_(filling_or_washing)',\n",
       " 'Bicycle_bell',\n",
       " 'Burping_and_eructation',\n",
       " 'Bus',\n",
       " 'Buzz',\n",
       " 'Car_passing_by',\n",
       " 'Cheering',\n",
       " 'Chewing_and_mastication',\n",
       " 'Child_speech_and_kid_speaking',\n",
       " 'Chink_and_clink',\n",
       " 'Chirp_and_tweet',\n",
       " 'Church_bell',\n",
       " 'Clapping',\n",
       " 'Computer_keyboard',\n",
       " 'Crackle',\n",
       " 'Cricket',\n",
       " 'Crowd',\n",
       " 'Cupboard_open_or_close',\n",
       " 'Cutlery_and_silverware',\n",
       " 'Dishes_and_pots_and_pans',\n",
       " 'Drawer_open_or_close',\n",
       " 'Drip',\n",
       " 'Electric_guitar',\n",
       " 'Fart',\n",
       " 'Female_singing',\n",
       " 'Female_speech_and_woman_speaking',\n",
       " 'Fill_(with_liquid)',\n",
       " 'Finger_snapping',\n",
       " 'Frying_(food)',\n",
       " 'Gasp',\n",
       " 'Glockenspiel',\n",
       " 'Gong',\n",
       " 'Gurgling',\n",
       " 'Harmonica',\n",
       " 'Hi-hat',\n",
       " 'Hiss',\n",
       " 'Keys_jangling',\n",
       " 'Knock',\n",
       " 'Male_singing',\n",
       " 'Male_speech_and_man_speaking',\n",
       " 'Marimba_and_xylophone',\n",
       " 'Mechanical_fan',\n",
       " 'Meow',\n",
       " 'Microwave_oven',\n",
       " 'Motorcycle',\n",
       " 'Printer',\n",
       " 'Purr',\n",
       " 'Race_car_and_auto_racing',\n",
       " 'Raindrop',\n",
       " 'Run',\n",
       " 'Scissors',\n",
       " 'Screaming',\n",
       " 'Shatter',\n",
       " 'Sigh',\n",
       " 'Sink_(filling_or_washing)',\n",
       " 'Skateboard',\n",
       " 'Slam',\n",
       " 'Sneeze',\n",
       " 'Squeak',\n",
       " 'Stream',\n",
       " 'Strum',\n",
       " 'Tap',\n",
       " 'Tick-tock',\n",
       " 'Toilet_flush',\n",
       " 'Traffic_noise_and_roadway_noise',\n",
       " 'Trickle_and_dribble',\n",
       " 'Walk_and_footsteps',\n",
       " 'Water_tap_and_faucet',\n",
       " 'Waves_and_surf',\n",
       " 'Whispering',\n",
       " 'Writing',\n",
       " 'Yell',\n",
       " 'Zipper_(clothing)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = test_df.columns[1:].tolist()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(labels)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8970, 80)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.zeros((len(train_df), num_classes)).astype(int)\n",
    "for i, row in enumerate(train_df['labels'].str.split(',')):\n",
    "    for label in row:\n",
    "        idx = labels.index(label)\n",
    "        y_train[i, idx] = 1\n",
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8970, 1120)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(mels['train_curated'], 'rb') as curated, open(mels['train_noisy'], 'rb') as noisy:\n",
    "    x_train = pickle.load(curated)\n",
    "    x_train.extend(pickle.load(noisy))\n",
    "\n",
    "with open(mels['test'], 'rb') as test:\n",
    "    x_test = pickle.load(test)\n",
    "    \n",
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FATTrainDataset(Dataset):\n",
    "    def __init__(self, mels, labels, transforms):\n",
    "        super().__init__()\n",
    "        self.mels = mels\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.mels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # crop 1sec\n",
    "        image = Image.fromarray(self.mels[idx], mode='RGB')        \n",
    "        time_dim, base_dim = image.size\n",
    "        crop = random.randint(0, time_dim - base_dim)\n",
    "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
    "        image = self.transforms(image).div_(255)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        label = torch.from_numpy(label).float()\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FATTestDataset(Dataset):\n",
    "    def __init__(self, fnames, mels, transforms, tta=5):\n",
    "        super().__init__()\n",
    "        self.fnames = fnames\n",
    "        self.mels = mels\n",
    "        self.transforms = transforms\n",
    "        self.tta = tta\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames) * self.tta\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        new_idx = idx % len(self.fnames)\n",
    "        \n",
    "        image = Image.fromarray(self.mels[new_idx], mode='RGB')\n",
    "        time_dim, base_dim = image.size\n",
    "        crop = random.randint(0, time_dim - base_dim)\n",
    "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
    "        image = self.transforms(image).div_(255)\n",
    "\n",
    "        fname = self.fnames[new_idx]\n",
    "        \n",
    "        return image, fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_dict = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(0.8),\n",
    "        transforms.RandomRotation(9, resample=False, expand=False, center=None),\n",
    "        transforms.RandomAffine(0, translate=(0.2,0), scale=None),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(0.8),\n",
    "        transforms.RandomRotation(5, resample=False, expand=False, center=None),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):    \n",
    "    def __init__(self, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),            \n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  \n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(p = 0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.1),\n",
    "            nn.Linear(128,num_classes),\n",
    "        )\n",
    " \n",
    "        for m in self.features.children():\n",
    "             if isinstance(m, nn.Conv2d):\n",
    "                 n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                 m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "             elif isinstance(m, nn.BatchNorm2d):\n",
    "                 m.weight.data.fill_(1)\n",
    "                 m.bias.data.zero_()\n",
    "         \n",
    "        for m in self.fc.children():\n",
    "             if isinstance(m, nn.Linear):\n",
    "                 nn.init.kaiming_uniform_(m.weight)\n",
    "             elif isinstance(m, nn.BatchNorm1d):\n",
    "                 m.weight.data.fill_(1)\n",
    "                 m.bias.data.zero_()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.mean(x, dim=3)\n",
    "        x, _ = torch.max(x, dim=2)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (21): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (23): ReLU(inplace)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Dropout(p=0.2)\n",
       "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace)\n",
       "    (4): Dropout(p=0.2)\n",
       "    (5): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Dropout(p=0.1)\n",
       "    (9): Linear(in_features=128, out_features=80, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, train_transforms):\n",
    "    num_epochs = 350\n",
    "    batch_size = 128\n",
    "    test_batch_size = 256\n",
    "    lr = 1e-3\n",
    "    eta_min = 1e-5\n",
    "    t_max = 5\n",
    "    \n",
    "    num_classes = y_train.shape[1]\n",
    "    \n",
    "    x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=SEED)\n",
    "    \n",
    "    train_dataset = FATTrainDataset(x_trn, y_trn, train_transforms)\n",
    "    valid_dataset = FATTrainDataset(x_val, y_val, train_transforms)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    model = Classifier(num_classes=num_classes).cuda()\n",
    "    criterion = nn.BCEWithLogitsLoss().cuda()\n",
    "    optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n",
    "\n",
    "    best_epoch = -1\n",
    "    best_lwlrap = 0.\n",
    "    mb = master_bar(range(num_epochs))\n",
    "\n",
    "    for epoch in mb:\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        avg_loss = 0.\n",
    "\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            preds = model(x_batch.cuda())\n",
    "            loss = criterion(preds, y_batch.cuda())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        valid_preds = np.zeros((len(x_val), num_classes))\n",
    "        avg_val_loss = 0.\n",
    "\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "            preds = model(x_batch.cuda()).detach()\n",
    "            loss = criterion(preds, y_batch.cuda())\n",
    "\n",
    "            preds = torch.sigmoid(preds)\n",
    "            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n",
    "\n",
    "            avg_val_loss += loss.item() / len(valid_loader)\n",
    "            \n",
    "        score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
    "        lwlrap = (score * weight).sum()\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            mb.write(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  val_lwlrap: {lwlrap:.6f}  time: {elapsed:.0f}s')\n",
    "    \n",
    "        if lwlrap > best_lwlrap:\n",
    "            best_epoch = epoch + 1\n",
    "            best_lwlrap = lwlrap\n",
    "            torch.save(model.state_dict(), 'weight_best_4.pt')\n",
    "            \n",
    "    return {\n",
    "        'best_epoch': best_epoch,\n",
    "        'best_lwlrap': best_lwlrap,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Epoch 1 - avg_train_loss: 0.3357  avg_val_loss: 0.1021  val_lwlrap: 0.067637  time: 29s<p>Epoch 2 - avg_train_loss: 0.0906  avg_val_loss: 0.0763  val_lwlrap: 0.091034  time: 29s<p>Epoch 3 - avg_train_loss: 0.0750  avg_val_loss: 0.0717  val_lwlrap: 0.110672  time: 29s<p>Epoch 4 - avg_train_loss: 0.0720  avg_val_loss: 0.0692  val_lwlrap: 0.129849  time: 29s<p>Epoch 5 - avg_train_loss: 0.0709  avg_val_loss: 0.0684  val_lwlrap: 0.145283  time: 29s<p>Epoch 6 - avg_train_loss: 0.0702  avg_val_loss: 0.0675  val_lwlrap: 0.155161  time: 29s<p>Epoch 7 - avg_train_loss: 0.0699  avg_val_loss: 0.0673  val_lwlrap: 0.156566  time: 29s<p>Epoch 8 - avg_train_loss: 0.0695  avg_val_loss: 0.0671  val_lwlrap: 0.158572  time: 29s<p>Epoch 9 - avg_train_loss: 0.0696  avg_val_loss: 0.0667  val_lwlrap: 0.167020  time: 29s<p>Epoch 10 - avg_train_loss: 0.0685  avg_val_loss: 0.0696  val_lwlrap: 0.126154  time: 29s<p>Epoch 11 - avg_train_loss: 0.0670  avg_val_loss: 0.0679  val_lwlrap: 0.155010  time: 29s<p>Epoch 12 - avg_train_loss: 0.0648  avg_val_loss: 0.0762  val_lwlrap: 0.071460  time: 29s<p>Epoch 13 - avg_train_loss: 0.0636  avg_val_loss: 0.0747  val_lwlrap: 0.129230  time: 29s<p>Epoch 14 - avg_train_loss: 0.0616  avg_val_loss: 0.0731  val_lwlrap: 0.139491  time: 29s<p>Epoch 15 - avg_train_loss: 0.0601  avg_val_loss: 0.0634  val_lwlrap: 0.231003  time: 29s<p>Epoch 16 - avg_train_loss: 0.0589  avg_val_loss: 0.0590  val_lwlrap: 0.300865  time: 29s<p>Epoch 17 - avg_train_loss: 0.0582  avg_val_loss: 0.0565  val_lwlrap: 0.356182  time: 29s<p>Epoch 18 - avg_train_loss: 0.0583  avg_val_loss: 0.0585  val_lwlrap: 0.323530  time: 29s<p>Epoch 19 - avg_train_loss: 0.0585  avg_val_loss: 0.0701  val_lwlrap: 0.170646  time: 29s<p>Epoch 20 - avg_train_loss: 0.0584  avg_val_loss: 0.0765  val_lwlrap: 0.093806  time: 29s<p>Epoch 21 - avg_train_loss: 0.0578  avg_val_loss: 0.0840  val_lwlrap: 0.078857  time: 29s<p>Epoch 22 - avg_train_loss: 0.0568  avg_val_loss: 0.0840  val_lwlrap: 0.068226  time: 29s<p>Epoch 23 - avg_train_loss: 0.0552  avg_val_loss: 0.0860  val_lwlrap: 0.092195  time: 29s<p>Epoch 24 - avg_train_loss: 0.0537  avg_val_loss: 0.0689  val_lwlrap: 0.186136  time: 29s<p>Epoch 25 - avg_train_loss: 0.0524  avg_val_loss: 0.0686  val_lwlrap: 0.199120  time: 29s<p>Epoch 26 - avg_train_loss: 0.0513  avg_val_loss: 0.0554  val_lwlrap: 0.380297  time: 29s<p>Epoch 27 - avg_train_loss: 0.0508  avg_val_loss: 0.0493  val_lwlrap: 0.461249  time: 29s<p>Epoch 28 - avg_train_loss: 0.0506  avg_val_loss: 0.0541  val_lwlrap: 0.394817  time: 29s<p>Epoch 29 - avg_train_loss: 0.0506  avg_val_loss: 0.0736  val_lwlrap: 0.161435  time: 29s<p>Epoch 30 - avg_train_loss: 0.0513  avg_val_loss: 0.0821  val_lwlrap: 0.085370  time: 29s<p>Epoch 31 - avg_train_loss: 0.0508  avg_val_loss: 0.1029  val_lwlrap: 0.079987  time: 29s<p>Epoch 32 - avg_train_loss: 0.0514  avg_val_loss: 0.0952  val_lwlrap: 0.068847  time: 29s<p>Epoch 33 - avg_train_loss: 0.0503  avg_val_loss: 0.0921  val_lwlrap: 0.068379  time: 29s<p>Epoch 34 - avg_train_loss: 0.0489  avg_val_loss: 0.0886  val_lwlrap: 0.130317  time: 29s<p>Epoch 35 - avg_train_loss: 0.0470  avg_val_loss: 0.0612  val_lwlrap: 0.275248  time: 29s<p>Epoch 36 - avg_train_loss: 0.0460  avg_val_loss: 0.0474  val_lwlrap: 0.487476  time: 29s<p>Epoch 37 - avg_train_loss: 0.0457  avg_val_loss: 0.0474  val_lwlrap: 0.515775  time: 29s<p>Epoch 38 - avg_train_loss: 0.0456  avg_val_loss: 0.0485  val_lwlrap: 0.483281  time: 29s<p>Epoch 39 - avg_train_loss: 0.0464  avg_val_loss: 0.0635  val_lwlrap: 0.308975  time: 29s<p>Epoch 40 - avg_train_loss: 0.0468  avg_val_loss: 0.1031  val_lwlrap: 0.080289  time: 29s<p>Epoch 41 - avg_train_loss: 0.0469  avg_val_loss: 0.0832  val_lwlrap: 0.094369  time: 29s<p>Epoch 42 - avg_train_loss: 0.0477  avg_val_loss: 0.0901  val_lwlrap: 0.100655  time: 29s<p>Epoch 43 - avg_train_loss: 0.0466  avg_val_loss: 0.0773  val_lwlrap: 0.147881  time: 29s<p>Epoch 44 - avg_train_loss: 0.0452  avg_val_loss: 0.1387  val_lwlrap: 0.093540  time: 29s<p>Epoch 45 - avg_train_loss: 0.0440  avg_val_loss: 0.0537  val_lwlrap: 0.405325  time: 29s<p>Epoch 46 - avg_train_loss: 0.0428  avg_val_loss: 0.0433  val_lwlrap: 0.534664  time: 29s<p>Epoch 47 - avg_train_loss: 0.0429  avg_val_loss: 0.0450  val_lwlrap: 0.541895  time: 29s<p>Epoch 48 - avg_train_loss: 0.0423  avg_val_loss: 0.0455  val_lwlrap: 0.537026  time: 29s<p>Epoch 49 - avg_train_loss: 0.0429  avg_val_loss: 0.0605  val_lwlrap: 0.357014  time: 29s<p>Epoch 50 - avg_train_loss: 0.0435  avg_val_loss: 0.0883  val_lwlrap: 0.099740  time: 29s<p>Epoch 51 - avg_train_loss: 0.0444  avg_val_loss: 0.0849  val_lwlrap: 0.152423  time: 29s<p>Epoch 52 - avg_train_loss: 0.0444  avg_val_loss: 0.1042  val_lwlrap: 0.079680  time: 29s<p>Epoch 53 - avg_train_loss: 0.0433  avg_val_loss: 0.0928  val_lwlrap: 0.106691  time: 29s<p>Epoch 54 - avg_train_loss: 0.0422  avg_val_loss: 0.0785  val_lwlrap: 0.177691  time: 29s<p>Epoch 55 - avg_train_loss: 0.0408  avg_val_loss: 0.0604  val_lwlrap: 0.297795  time: 29s<p>Epoch 56 - avg_train_loss: 0.0402  avg_val_loss: 0.0417  val_lwlrap: 0.562847  time: 29s<p>Epoch 57 - avg_train_loss: 0.0393  avg_val_loss: 0.0426  val_lwlrap: 0.570852  time: 29s<p>Epoch 58 - avg_train_loss: 0.0394  avg_val_loss: 0.0432  val_lwlrap: 0.566239  time: 29s<p>Epoch 59 - avg_train_loss: 0.0402  avg_val_loss: 0.0474  val_lwlrap: 0.499729  time: 29s<p>Epoch 60 - avg_train_loss: 0.0409  avg_val_loss: 0.0851  val_lwlrap: 0.151433  time: 29s<p>Epoch 61 - avg_train_loss: 0.0425  avg_val_loss: 0.0905  val_lwlrap: 0.172786  time: 29s<p>Epoch 62 - avg_train_loss: 0.0417  avg_val_loss: 0.1640  val_lwlrap: 0.079059  time: 29s<p>Epoch 63 - avg_train_loss: 0.0414  avg_val_loss: 0.1019  val_lwlrap: 0.135486  time: 29s<p>Epoch 64 - avg_train_loss: 0.0403  avg_val_loss: 0.0922  val_lwlrap: 0.153218  time: 29s<p>Epoch 65 - avg_train_loss: 0.0387  avg_val_loss: 0.0646  val_lwlrap: 0.335569  time: 29s<p>Epoch 66 - avg_train_loss: 0.0377  avg_val_loss: 0.0406  val_lwlrap: 0.582586  time: 29s<p>Epoch 67 - avg_train_loss: 0.0375  avg_val_loss: 0.0415  val_lwlrap: 0.580763  time: 29s<p>Epoch 68 - avg_train_loss: 0.0373  avg_val_loss: 0.0405  val_lwlrap: 0.587281  time: 29s<p>Epoch 69 - avg_train_loss: 0.0377  avg_val_loss: 0.0463  val_lwlrap: 0.494865  time: 29s<p>Epoch 70 - avg_train_loss: 0.0379  avg_val_loss: 0.0694  val_lwlrap: 0.263045  time: 29s<p>Epoch 71 - avg_train_loss: 0.0397  avg_val_loss: 0.1482  val_lwlrap: 0.066857  time: 29s<p>Epoch 72 - avg_train_loss: 0.0400  avg_val_loss: 0.1211  val_lwlrap: 0.102093  time: 29s<p>Epoch 73 - avg_train_loss: 0.0392  avg_val_loss: 0.0814  val_lwlrap: 0.252953  time: 29s<p>Epoch 74 - avg_train_loss: 0.0383  avg_val_loss: 0.1062  val_lwlrap: 0.210515  time: 29s<p>Epoch 75 - avg_train_loss: 0.0368  avg_val_loss: 0.0626  val_lwlrap: 0.313739  time: 29s<p>Epoch 76 - avg_train_loss: 0.0354  avg_val_loss: 0.0395  val_lwlrap: 0.591886  time: 29s<p>Epoch 77 - avg_train_loss: 0.0350  avg_val_loss: 0.0402  val_lwlrap: 0.601575  time: 29s<p>Epoch 78 - avg_train_loss: 0.0349  avg_val_loss: 0.0397  val_lwlrap: 0.602803  time: 29s<p>Epoch 79 - avg_train_loss: 0.0360  avg_val_loss: 0.0550  val_lwlrap: 0.410282  time: 29s<p>Epoch 80 - avg_train_loss: 0.0363  avg_val_loss: 0.1303  val_lwlrap: 0.098164  time: 29s<p>Epoch 81 - avg_train_loss: 0.0368  avg_val_loss: 0.1106  val_lwlrap: 0.145565  time: 29s<p>Epoch 82 - avg_train_loss: 0.0379  avg_val_loss: 0.2130  val_lwlrap: 0.087802  time: 29s<p>Epoch 83 - avg_train_loss: 0.0367  avg_val_loss: 0.0865  val_lwlrap: 0.181435  time: 29s<p>Epoch 84 - avg_train_loss: 0.0359  avg_val_loss: 0.1427  val_lwlrap: 0.178938  time: 29s<p>Epoch 85 - avg_train_loss: 0.0346  avg_val_loss: 0.0475  val_lwlrap: 0.518414  time: 29s<p>Epoch 86 - avg_train_loss: 0.0336  avg_val_loss: 0.0407  val_lwlrap: 0.605806  time: 29s<p>Epoch 87 - avg_train_loss: 0.0328  avg_val_loss: 0.0371  val_lwlrap: 0.616926  time: 29s<p>Epoch 88 - avg_train_loss: 0.0334  avg_val_loss: 0.0416  val_lwlrap: 0.575175  time: 29s<p>Epoch 89 - avg_train_loss: 0.0339  avg_val_loss: 0.0780  val_lwlrap: 0.299691  time: 29s<p>Epoch 90 - avg_train_loss: 0.0346  avg_val_loss: 0.0832  val_lwlrap: 0.178085  time: 29s<p>Epoch 91 - avg_train_loss: 0.0358  avg_val_loss: 0.0973  val_lwlrap: 0.192554  time: 29s<p>Epoch 92 - avg_train_loss: 0.0357  avg_val_loss: 0.1510  val_lwlrap: 0.078232  time: 29s<p>Epoch 93 - avg_train_loss: 0.0356  avg_val_loss: 0.0751  val_lwlrap: 0.177098  time: 29s<p>Epoch 94 - avg_train_loss: 0.0340  avg_val_loss: 0.1871  val_lwlrap: 0.078779  time: 29s<p>Epoch 95 - avg_train_loss: 0.0326  avg_val_loss: 0.0842  val_lwlrap: 0.306662  time: 29s<p>Epoch 96 - avg_train_loss: 0.0316  avg_val_loss: 0.0426  val_lwlrap: 0.585835  time: 29s<p>Epoch 97 - avg_train_loss: 0.0308  avg_val_loss: 0.0367  val_lwlrap: 0.618656  time: 29s<p>Epoch 98 - avg_train_loss: 0.0317  avg_val_loss: 0.0428  val_lwlrap: 0.578923  time: 29s<p>Epoch 99 - avg_train_loss: 0.0318  avg_val_loss: 0.0725  val_lwlrap: 0.330322  time: 29s<p>Epoch 100 - avg_train_loss: 0.0328  avg_val_loss: 0.1060  val_lwlrap: 0.138184  time: 29s<p>Epoch 101 - avg_train_loss: 0.0346  avg_val_loss: 0.1712  val_lwlrap: 0.097150  time: 29s<p>Epoch 102 - avg_train_loss: 0.0348  avg_val_loss: 0.1639  val_lwlrap: 0.075139  time: 29s<p>Epoch 103 - avg_train_loss: 0.0341  avg_val_loss: 0.1672  val_lwlrap: 0.104269  time: 29s<p>Epoch 104 - avg_train_loss: 0.0325  avg_val_loss: 0.0952  val_lwlrap: 0.272748  time: 29s<p>Epoch 105 - avg_train_loss: 0.0316  avg_val_loss: 0.0445  val_lwlrap: 0.529049  time: 29s<p>Epoch 106 - avg_train_loss: 0.0305  avg_val_loss: 0.0382  val_lwlrap: 0.614658  time: 29s<p>Epoch 107 - avg_train_loss: 0.0299  avg_val_loss: 0.0378  val_lwlrap: 0.625009  time: 29s<p>Epoch 108 - avg_train_loss: 0.0300  avg_val_loss: 0.0384  val_lwlrap: 0.611395  time: 29s<p>Epoch 109 - avg_train_loss: 0.0303  avg_val_loss: 0.0629  val_lwlrap: 0.347094  time: 29s<p>Epoch 110 - avg_train_loss: 0.0306  avg_val_loss: 0.0895  val_lwlrap: 0.166899  time: 29s<p>Epoch 111 - avg_train_loss: 0.0316  avg_val_loss: 0.1225  val_lwlrap: 0.177388  time: 29s<p>Epoch 112 - avg_train_loss: 0.0334  avg_val_loss: 0.1469  val_lwlrap: 0.068330  time: 29s<p>Epoch 113 - avg_train_loss: 0.0324  avg_val_loss: 0.1477  val_lwlrap: 0.120172  time: 29s<p>Epoch 114 - avg_train_loss: 0.0304  avg_val_loss: 0.0786  val_lwlrap: 0.224974  time: 29s<p>Epoch 115 - avg_train_loss: 0.0293  avg_val_loss: 0.0694  val_lwlrap: 0.343390  time: 29s<p>Epoch 116 - avg_train_loss: 0.0285  avg_val_loss: 0.0394  val_lwlrap: 0.609417  time: 29s<p>Epoch 117 - avg_train_loss: 0.0284  avg_val_loss: 0.0377  val_lwlrap: 0.638193  time: 29s<p>Epoch 118 - avg_train_loss: 0.0282  avg_val_loss: 0.0393  val_lwlrap: 0.608805  time: 29s<p>Epoch 119 - avg_train_loss: 0.0291  avg_val_loss: 0.0553  val_lwlrap: 0.460740  time: 29s<p>Epoch 120 - avg_train_loss: 0.0302  avg_val_loss: 0.0919  val_lwlrap: 0.118991  time: 29s<p>Epoch 121 - avg_train_loss: 0.0307  avg_val_loss: 0.1928  val_lwlrap: 0.064320  time: 29s<p>Epoch 122 - avg_train_loss: 0.0325  avg_val_loss: 0.1373  val_lwlrap: 0.122073  time: 29s<p>Epoch 123 - avg_train_loss: 0.0309  avg_val_loss: 0.0995  val_lwlrap: 0.235591  time: 29s<p>Epoch 124 - avg_train_loss: 0.0300  avg_val_loss: 0.0921  val_lwlrap: 0.233227  time: 29s<p>Epoch 125 - avg_train_loss: 0.0282  avg_val_loss: 0.0556  val_lwlrap: 0.409354  time: 29s<p>Epoch 126 - avg_train_loss: 0.0277  avg_val_loss: 0.0390  val_lwlrap: 0.618600  time: 29s<p>Epoch 127 - avg_train_loss: 0.0266  avg_val_loss: 0.0363  val_lwlrap: 0.636298  time: 29s<p>Epoch 128 - avg_train_loss: 0.0270  avg_val_loss: 0.0393  val_lwlrap: 0.617330  time: 29s<p>Epoch 129 - avg_train_loss: 0.0272  avg_val_loss: 0.0595  val_lwlrap: 0.404743  time: 29s<p>Epoch 130 - avg_train_loss: 0.0283  avg_val_loss: 0.1264  val_lwlrap: 0.105011  time: 29s<p>Epoch 131 - avg_train_loss: 0.0297  avg_val_loss: 0.1047  val_lwlrap: 0.082172  time: 29s<p>Epoch 132 - avg_train_loss: 0.0309  avg_val_loss: 0.1836  val_lwlrap: 0.093892  time: 29s<p>Epoch 133 - avg_train_loss: 0.0301  avg_val_loss: 0.2299  val_lwlrap: 0.082321  time: 29s<p>Epoch 134 - avg_train_loss: 0.0285  avg_val_loss: 0.1063  val_lwlrap: 0.253940  time: 29s<p>Epoch 135 - avg_train_loss: 0.0269  avg_val_loss: 0.1322  val_lwlrap: 0.191835  time: 29s<p>Epoch 136 - avg_train_loss: 0.0258  avg_val_loss: 0.0400  val_lwlrap: 0.620259  time: 29s<p>Epoch 137 - avg_train_loss: 0.0255  avg_val_loss: 0.0376  val_lwlrap: 0.635951  time: 29s<p>Epoch 138 - avg_train_loss: 0.0257  avg_val_loss: 0.0377  val_lwlrap: 0.626771  time: 29s<p>Epoch 139 - avg_train_loss: 0.0266  avg_val_loss: 0.0570  val_lwlrap: 0.472668  time: 29s<p>Epoch 140 - avg_train_loss: 0.0272  avg_val_loss: 0.1061  val_lwlrap: 0.168483  time: 29s<p>Epoch 141 - avg_train_loss: 0.0281  avg_val_loss: 0.0824  val_lwlrap: 0.163939  time: 29s<p>Epoch 142 - avg_train_loss: 0.0294  avg_val_loss: 0.1630  val_lwlrap: 0.110367  time: 29s<p>Epoch 143 - avg_train_loss: 0.0277  avg_val_loss: 0.2228  val_lwlrap: 0.086610  time: 29s<p>Epoch 144 - avg_train_loss: 0.0274  avg_val_loss: 0.0994  val_lwlrap: 0.118721  time: 29s<p>Epoch 145 - avg_train_loss: 0.0258  avg_val_loss: 0.0500  val_lwlrap: 0.487000  time: 29s<p>Epoch 146 - avg_train_loss: 0.0246  avg_val_loss: 0.0373  val_lwlrap: 0.635055  time: 29s<p>Epoch 147 - avg_train_loss: 0.0243  avg_val_loss: 0.0383  val_lwlrap: 0.654802  time: 29s<p>Epoch 148 - avg_train_loss: 0.0243  avg_val_loss: 0.0393  val_lwlrap: 0.612539  time: 29s<p>Epoch 149 - avg_train_loss: 0.0249  avg_val_loss: 0.0761  val_lwlrap: 0.355669  time: 29s<p>Epoch 150 - avg_train_loss: 0.0259  avg_val_loss: 0.0808  val_lwlrap: 0.213101  time: 29s<p>Epoch 151 - avg_train_loss: 0.0276  avg_val_loss: 0.2771  val_lwlrap: 0.072368  time: 29s<p>Epoch 152 - avg_train_loss: 0.0277  avg_val_loss: 0.4045  val_lwlrap: 0.062642  time: 29s<p>Epoch 153 - avg_train_loss: 0.0265  avg_val_loss: 0.1397  val_lwlrap: 0.089718  time: 29s<p>Epoch 154 - avg_train_loss: 0.0254  avg_val_loss: 0.0891  val_lwlrap: 0.170661  time: 29s<p>Epoch 155 - avg_train_loss: 0.0242  avg_val_loss: 0.0599  val_lwlrap: 0.460268  time: 29s<p>Epoch 156 - avg_train_loss: 0.0234  avg_val_loss: 0.0420  val_lwlrap: 0.593367  time: 29s<p>Epoch 157 - avg_train_loss: 0.0231  avg_val_loss: 0.0370  val_lwlrap: 0.656059  time: 29s<p>Epoch 158 - avg_train_loss: 0.0229  avg_val_loss: 0.0416  val_lwlrap: 0.606898  time: 29s<p>Epoch 159 - avg_train_loss: 0.0238  avg_val_loss: 0.0553  val_lwlrap: 0.488330  time: 29s<p>Epoch 160 - avg_train_loss: 0.0249  avg_val_loss: 0.2207  val_lwlrap: 0.103379  time: 29s<p>Epoch 161 - avg_train_loss: 0.0256  avg_val_loss: 0.1470  val_lwlrap: 0.085068  time: 29s<p>Epoch 162 - avg_train_loss: 0.0256  avg_val_loss: 0.2930  val_lwlrap: 0.077515  time: 29s<p>Epoch 163 - avg_train_loss: 0.0249  avg_val_loss: 0.1310  val_lwlrap: 0.158679  time: 29s<p>Epoch 164 - avg_train_loss: 0.0241  avg_val_loss: 0.1043  val_lwlrap: 0.088421  time: 29s<p>Epoch 165 - avg_train_loss: 0.0230  avg_val_loss: 0.0508  val_lwlrap: 0.531801  time: 29s<p>Epoch 166 - avg_train_loss: 0.0226  avg_val_loss: 0.0460  val_lwlrap: 0.566948  time: 29s<p>Epoch 167 - avg_train_loss: 0.0215  avg_val_loss: 0.0353  val_lwlrap: 0.657410  time: 29s<p>Epoch 168 - avg_train_loss: 0.0217  avg_val_loss: 0.0426  val_lwlrap: 0.609736  time: 29s<p>Epoch 169 - avg_train_loss: 0.0220  avg_val_loss: 0.0518  val_lwlrap: 0.497582  time: 29s<p>Epoch 170 - avg_train_loss: 0.0236  avg_val_loss: 0.1452  val_lwlrap: 0.136482  time: 29s<p>Epoch 171 - avg_train_loss: 0.0252  avg_val_loss: 0.1417  val_lwlrap: 0.142638  time: 29s<p>Epoch 172 - avg_train_loss: 0.0261  avg_val_loss: 0.1804  val_lwlrap: 0.091942  time: 29s<p>Epoch 173 - avg_train_loss: 0.0252  avg_val_loss: 0.1036  val_lwlrap: 0.142403  time: 29s<p>Epoch 174 - avg_train_loss: 0.0238  avg_val_loss: 0.1262  val_lwlrap: 0.200217  time: 29s<p>Epoch 175 - avg_train_loss: 0.0221  avg_val_loss: 0.0491  val_lwlrap: 0.508006  time: 29s<p>Epoch 176 - avg_train_loss: 0.0211  avg_val_loss: 0.0383  val_lwlrap: 0.650274  time: 29s<p>Epoch 177 - avg_train_loss: 0.0208  avg_val_loss: 0.0344  val_lwlrap: 0.665564  time: 29s<p>Epoch 178 - avg_train_loss: 0.0207  avg_val_loss: 0.0381  val_lwlrap: 0.640796  time: 29s<p>Epoch 179 - avg_train_loss: 0.0214  avg_val_loss: 0.0680  val_lwlrap: 0.429211  time: 29s<p>Epoch 180 - avg_train_loss: 0.0226  avg_val_loss: 0.0811  val_lwlrap: 0.184888  time: 29s<p>Epoch 181 - avg_train_loss: 0.0237  avg_val_loss: 0.1722  val_lwlrap: 0.070902  time: 29s<p>Epoch 182 - avg_train_loss: 0.0232  avg_val_loss: 0.2503  val_lwlrap: 0.067667  time: 29s<p>Epoch 183 - avg_train_loss: 0.0237  avg_val_loss: 0.1591  val_lwlrap: 0.160173  time: 29s<p>Epoch 184 - avg_train_loss: 0.0227  avg_val_loss: 0.1225  val_lwlrap: 0.204994  time: 29s<p>Epoch 185 - avg_train_loss: 0.0211  avg_val_loss: 0.0487  val_lwlrap: 0.513894  time: 29s<p>Epoch 186 - avg_train_loss: 0.0199  avg_val_loss: 0.0414  val_lwlrap: 0.634198  time: 29s<p>Epoch 187 - avg_train_loss: 0.0197  avg_val_loss: 0.0378  val_lwlrap: 0.647900  time: 29s<p>Epoch 188 - avg_train_loss: 0.0200  avg_val_loss: 0.0408  val_lwlrap: 0.632743  time: 29s<p>Epoch 189 - avg_train_loss: 0.0200  avg_val_loss: 0.0443  val_lwlrap: 0.586870  time: 29s<p>Epoch 190 - avg_train_loss: 0.0209  avg_val_loss: 0.0796  val_lwlrap: 0.233592  time: 29s<p>Epoch 191 - avg_train_loss: 0.0222  avg_val_loss: 0.1419  val_lwlrap: 0.109996  time: 29s<p>Epoch 192 - avg_train_loss: 0.0232  avg_val_loss: 0.0911  val_lwlrap: 0.162225  time: 29s<p>Epoch 193 - avg_train_loss: 0.0221  avg_val_loss: 0.1853  val_lwlrap: 0.118809  time: 29s<p>Epoch 194 - avg_train_loss: 0.0220  avg_val_loss: 0.1072  val_lwlrap: 0.167603  time: 29s<p>Epoch 195 - avg_train_loss: 0.0202  avg_val_loss: 0.0493  val_lwlrap: 0.561250  time: 29s<p>Epoch 196 - avg_train_loss: 0.0184  avg_val_loss: 0.0409  val_lwlrap: 0.632675  time: 29s<p>Epoch 197 - avg_train_loss: 0.0185  avg_val_loss: 0.0382  val_lwlrap: 0.661231  time: 29s<p>Epoch 198 - avg_train_loss: 0.0187  avg_val_loss: 0.0365  val_lwlrap: 0.655356  time: 29s<p>Epoch 199 - avg_train_loss: 0.0190  avg_val_loss: 0.0615  val_lwlrap: 0.467074  time: 29s<p>Epoch 200 - avg_train_loss: 0.0202  avg_val_loss: 0.1508  val_lwlrap: 0.124683  time: 29s<p>Epoch 201 - avg_train_loss: 0.0208  avg_val_loss: 0.1702  val_lwlrap: 0.086436  time: 29s<p>Epoch 202 - avg_train_loss: 0.0227  avg_val_loss: 0.1358  val_lwlrap: 0.076958  time: 29s<p>Epoch 203 - avg_train_loss: 0.0213  avg_val_loss: 0.1280  val_lwlrap: 0.135321  time: 29s<p>Epoch 204 - avg_train_loss: 0.0209  avg_val_loss: 0.0833  val_lwlrap: 0.286055  time: 29s<p>Epoch 205 - avg_train_loss: 0.0201  avg_val_loss: 0.0654  val_lwlrap: 0.381349  time: 29s<p>Epoch 206 - avg_train_loss: 0.0185  avg_val_loss: 0.0370  val_lwlrap: 0.653807  time: 29s<p>Epoch 207 - avg_train_loss: 0.0182  avg_val_loss: 0.0386  val_lwlrap: 0.663086  time: 29s<p>Epoch 208 - avg_train_loss: 0.0178  avg_val_loss: 0.0355  val_lwlrap: 0.660939  time: 29s<p>Epoch 209 - avg_train_loss: 0.0190  avg_val_loss: 0.0532  val_lwlrap: 0.538907  time: 29s<p>Epoch 210 - avg_train_loss: 0.0203  avg_val_loss: 0.1172  val_lwlrap: 0.167769  time: 29s<p>Epoch 211 - avg_train_loss: 0.0210  avg_val_loss: 0.1320  val_lwlrap: 0.224668  time: 29s<p>Epoch 212 - avg_train_loss: 0.0222  avg_val_loss: 0.1272  val_lwlrap: 0.148301  time: 29s<p>Epoch 213 - avg_train_loss: 0.0236  avg_val_loss: 0.1729  val_lwlrap: 0.086033  time: 29s<p>Epoch 214 - avg_train_loss: 0.0215  avg_val_loss: 0.0930  val_lwlrap: 0.239401  time: 29s<p>Epoch 215 - avg_train_loss: 0.0196  avg_val_loss: 0.1269  val_lwlrap: 0.318609  time: 29s<p>Epoch 216 - avg_train_loss: 0.0185  avg_val_loss: 0.0391  val_lwlrap: 0.650321  time: 29s<p>Epoch 217 - avg_train_loss: 0.0180  avg_val_loss: 0.0396  val_lwlrap: 0.660908  time: 29s<p>Epoch 218 - avg_train_loss: 0.0179  avg_val_loss: 0.0418  val_lwlrap: 0.612739  time: 29s<p>Epoch 219 - avg_train_loss: 0.0182  avg_val_loss: 0.0640  val_lwlrap: 0.469855  time: 29s<p>Epoch 220 - avg_train_loss: 0.0189  avg_val_loss: 0.1069  val_lwlrap: 0.166367  time: 29s<p>Epoch 221 - avg_train_loss: 0.0201  avg_val_loss: 0.1205  val_lwlrap: 0.081981  time: 29s<p>Epoch 222 - avg_train_loss: 0.0202  avg_val_loss: 0.1150  val_lwlrap: 0.068869  time: 29s<p>Epoch 223 - avg_train_loss: 0.0188  avg_val_loss: 0.1377  val_lwlrap: 0.068497  time: 29s<p>Epoch 224 - avg_train_loss: 0.0188  avg_val_loss: 0.0854  val_lwlrap: 0.239398  time: 29s<p>Epoch 225 - avg_train_loss: 0.0172  avg_val_loss: 0.0868  val_lwlrap: 0.361706  time: 29s<p>Epoch 226 - avg_train_loss: 0.0166  avg_val_loss: 0.0379  val_lwlrap: 0.659662  time: 29s<p>Epoch 227 - avg_train_loss: 0.0164  avg_val_loss: 0.0380  val_lwlrap: 0.669203  time: 29s<p>Epoch 228 - avg_train_loss: 0.0167  avg_val_loss: 0.0404  val_lwlrap: 0.637888  time: 29s<p>Epoch 229 - avg_train_loss: 0.0164  avg_val_loss: 0.0630  val_lwlrap: 0.458339  time: 29s<p>Epoch 230 - avg_train_loss: 0.0170  avg_val_loss: 0.0812  val_lwlrap: 0.325473  time: 29s<p>Epoch 231 - avg_train_loss: 0.0185  avg_val_loss: 0.1883  val_lwlrap: 0.121444  time: 29s<p>Epoch 232 - avg_train_loss: 0.0202  avg_val_loss: 0.1365  val_lwlrap: 0.097715  time: 29s<p>Epoch 233 - avg_train_loss: 0.0190  avg_val_loss: 0.1163  val_lwlrap: 0.164441  time: 29s<p>Epoch 234 - avg_train_loss: 0.0183  avg_val_loss: 0.0994  val_lwlrap: 0.302763  time: 29s<p>Epoch 235 - avg_train_loss: 0.0173  avg_val_loss: 0.0715  val_lwlrap: 0.404471  time: 29s<p>Epoch 236 - avg_train_loss: 0.0164  avg_val_loss: 0.0459  val_lwlrap: 0.607381  time: 29s<p>Epoch 237 - avg_train_loss: 0.0154  avg_val_loss: 0.0395  val_lwlrap: 0.662588  time: 29s<p>Epoch 238 - avg_train_loss: 0.0158  avg_val_loss: 0.0411  val_lwlrap: 0.657534  time: 29s<p>Epoch 239 - avg_train_loss: 0.0167  avg_val_loss: 0.0689  val_lwlrap: 0.449924  time: 29s<p>Epoch 240 - avg_train_loss: 0.0173  avg_val_loss: 0.0867  val_lwlrap: 0.172489  time: 29s<p>Epoch 241 - avg_train_loss: 0.0185  avg_val_loss: 0.1558  val_lwlrap: 0.132574  time: 29s<p>Epoch 242 - avg_train_loss: 0.0186  avg_val_loss: 0.1074  val_lwlrap: 0.167900  time: 29s<p>Epoch 243 - avg_train_loss: 0.0180  avg_val_loss: 0.0756  val_lwlrap: 0.290322  time: 29s<p>Epoch 244 - avg_train_loss: 0.0169  avg_val_loss: 0.0936  val_lwlrap: 0.313888  time: 29s<p>Epoch 245 - avg_train_loss: 0.0161  avg_val_loss: 0.0466  val_lwlrap: 0.576533  time: 29s<p>Epoch 246 - avg_train_loss: 0.0157  avg_val_loss: 0.0405  val_lwlrap: 0.652844  time: 29s<p>Epoch 247 - avg_train_loss: 0.0146  avg_val_loss: 0.0395  val_lwlrap: 0.670287  time: 29s<p>Epoch 248 - avg_train_loss: 0.0151  avg_val_loss: 0.0420  val_lwlrap: 0.640161  time: 29s<p>Epoch 249 - avg_train_loss: 0.0154  avg_val_loss: 0.0986  val_lwlrap: 0.246184  time: 29s<p>Epoch 250 - avg_train_loss: 0.0162  avg_val_loss: 0.1399  val_lwlrap: 0.208680  time: 29s<p>Epoch 251 - avg_train_loss: 0.0179  avg_val_loss: 0.1602  val_lwlrap: 0.102819  time: 29s<p>Epoch 252 - avg_train_loss: 0.0187  avg_val_loss: 0.2180  val_lwlrap: 0.080845  time: 29s<p>Epoch 253 - avg_train_loss: 0.0185  avg_val_loss: 0.1536  val_lwlrap: 0.091087  time: 29s<p>Epoch 254 - avg_train_loss: 0.0165  avg_val_loss: 0.0958  val_lwlrap: 0.251820  time: 29s<p>Epoch 255 - avg_train_loss: 0.0157  avg_val_loss: 0.0613  val_lwlrap: 0.466108  time: 29s<p>Epoch 256 - avg_train_loss: 0.0150  avg_val_loss: 0.0379  val_lwlrap: 0.667492  time: 29s<p>Epoch 257 - avg_train_loss: 0.0143  avg_val_loss: 0.0392  val_lwlrap: 0.671214  time: 29s<p>Epoch 258 - avg_train_loss: 0.0145  avg_val_loss: 0.0397  val_lwlrap: 0.647345  time: 29s<p>Epoch 259 - avg_train_loss: 0.0147  avg_val_loss: 0.0518  val_lwlrap: 0.541341  time: 29s<p>Epoch 260 - avg_train_loss: 0.0151  avg_val_loss: 0.0805  val_lwlrap: 0.278915  time: 29s<p>Epoch 261 - avg_train_loss: 0.0163  avg_val_loss: 0.1104  val_lwlrap: 0.260015  time: 29s<p>Epoch 262 - avg_train_loss: 0.0168  avg_val_loss: 0.1150  val_lwlrap: 0.155626  time: 29s<p>Epoch 263 - avg_train_loss: 0.0171  avg_val_loss: 0.1059  val_lwlrap: 0.210614  time: 29s<p>Epoch 264 - avg_train_loss: 0.0165  avg_val_loss: 0.1053  val_lwlrap: 0.279449  time: 29s<p>Epoch 265 - avg_train_loss: 0.0152  avg_val_loss: 0.0622  val_lwlrap: 0.499783  time: 29s<p>Epoch 266 - avg_train_loss: 0.0142  avg_val_loss: 0.0390  val_lwlrap: 0.650751  time: 29s<p>Epoch 267 - avg_train_loss: 0.0139  avg_val_loss: 0.0391  val_lwlrap: 0.670375  time: 29s<p>Epoch 268 - avg_train_loss: 0.0143  avg_val_loss: 0.0400  val_lwlrap: 0.649913  time: 29s<p>Epoch 269 - avg_train_loss: 0.0142  avg_val_loss: 0.0751  val_lwlrap: 0.397824  time: 29s<p>Epoch 270 - avg_train_loss: 0.0151  avg_val_loss: 0.1028  val_lwlrap: 0.236634  time: 29s<p>Epoch 271 - avg_train_loss: 0.0170  avg_val_loss: 0.1627  val_lwlrap: 0.093874  time: 29s<p>Epoch 272 - avg_train_loss: 0.0181  avg_val_loss: 0.1550  val_lwlrap: 0.134716  time: 29s<p>Epoch 273 - avg_train_loss: 0.0163  avg_val_loss: 0.1405  val_lwlrap: 0.093347  time: 29s<p>Epoch 274 - avg_train_loss: 0.0156  avg_val_loss: 0.0891  val_lwlrap: 0.338954  time: 29s<p>Epoch 275 - avg_train_loss: 0.0149  avg_val_loss: 0.0868  val_lwlrap: 0.257802  time: 29s<p>Epoch 276 - avg_train_loss: 0.0137  avg_val_loss: 0.0417  val_lwlrap: 0.652920  time: 29s<p>Epoch 277 - avg_train_loss: 0.0133  avg_val_loss: 0.0404  val_lwlrap: 0.662418  time: 29s<p>Epoch 278 - avg_train_loss: 0.0136  avg_val_loss: 0.0435  val_lwlrap: 0.628029  time: 29s<p>Epoch 279 - avg_train_loss: 0.0139  avg_val_loss: 0.0644  val_lwlrap: 0.474423  time: 29s<p>Epoch 280 - avg_train_loss: 0.0151  avg_val_loss: 0.0790  val_lwlrap: 0.297389  time: 29s<p>Epoch 281 - avg_train_loss: 0.0159  avg_val_loss: 0.0793  val_lwlrap: 0.253765  time: 29s<p>Epoch 282 - avg_train_loss: 0.0159  avg_val_loss: 0.1739  val_lwlrap: 0.086408  time: 29s<p>Epoch 283 - avg_train_loss: 0.0161  avg_val_loss: 0.1114  val_lwlrap: 0.158349  time: 29s<p>Epoch 284 - avg_train_loss: 0.0161  avg_val_loss: 0.1326  val_lwlrap: 0.219197  time: 29s<p>Epoch 285 - avg_train_loss: 0.0146  avg_val_loss: 0.0620  val_lwlrap: 0.499775  time: 29s<p>Epoch 286 - avg_train_loss: 0.0136  avg_val_loss: 0.0447  val_lwlrap: 0.656634  time: 29s<p>Epoch 287 - avg_train_loss: 0.0137  avg_val_loss: 0.0412  val_lwlrap: 0.661352  time: 29s<p>Epoch 288 - avg_train_loss: 0.0130  avg_val_loss: 0.0429  val_lwlrap: 0.636651  time: 29s<p>Epoch 289 - avg_train_loss: 0.0138  avg_val_loss: 0.0892  val_lwlrap: 0.302374  time: 29s<p>Epoch 290 - avg_train_loss: 0.0143  avg_val_loss: 0.1318  val_lwlrap: 0.149732  time: 29s<p>Epoch 291 - avg_train_loss: 0.0156  avg_val_loss: 0.1476  val_lwlrap: 0.109332  time: 29s<p>Epoch 292 - avg_train_loss: 0.0160  avg_val_loss: 0.1201  val_lwlrap: 0.139208  time: 29s<p>Epoch 293 - avg_train_loss: 0.0158  avg_val_loss: 0.1403  val_lwlrap: 0.114562  time: 29s<p>Epoch 294 - avg_train_loss: 0.0152  avg_val_loss: 0.1071  val_lwlrap: 0.285081  time: 29s<p>Epoch 295 - avg_train_loss: 0.0140  avg_val_loss: 0.0873  val_lwlrap: 0.402259  time: 29s<p>Epoch 296 - avg_train_loss: 0.0129  avg_val_loss: 0.0476  val_lwlrap: 0.587866  time: 29s<p>Epoch 297 - avg_train_loss: 0.0123  avg_val_loss: 0.0398  val_lwlrap: 0.668272  time: 29s<p>Epoch 298 - avg_train_loss: 0.0125  avg_val_loss: 0.0439  val_lwlrap: 0.631918  time: 29s<p>Epoch 299 - avg_train_loss: 0.0131  avg_val_loss: 0.0519  val_lwlrap: 0.529604  time: 29s<p>Epoch 300 - avg_train_loss: 0.0144  avg_val_loss: 0.0877  val_lwlrap: 0.320743  time: 29s<p>Epoch 301 - avg_train_loss: 0.0146  avg_val_loss: 0.1214  val_lwlrap: 0.144148  time: 29s<p>Epoch 302 - avg_train_loss: 0.0146  avg_val_loss: 0.0946  val_lwlrap: 0.150987  time: 29s<p>Epoch 303 - avg_train_loss: 0.0148  avg_val_loss: 0.1018  val_lwlrap: 0.214979  time: 29s<p>Epoch 304 - avg_train_loss: 0.0135  avg_val_loss: 0.1208  val_lwlrap: 0.172941  time: 29s<p>Epoch 305 - avg_train_loss: 0.0131  avg_val_loss: 0.0756  val_lwlrap: 0.463937  time: 29s<p>Epoch 306 - avg_train_loss: 0.0122  avg_val_loss: 0.0438  val_lwlrap: 0.649050  time: 29s<p>Epoch 307 - avg_train_loss: 0.0118  avg_val_loss: 0.0406  val_lwlrap: 0.664157  time: 29s<p>Epoch 308 - avg_train_loss: 0.0120  avg_val_loss: 0.0425  val_lwlrap: 0.644905  time: 29s<p>Epoch 309 - avg_train_loss: 0.0131  avg_val_loss: 0.0583  val_lwlrap: 0.524916  time: 29s<p>Epoch 310 - avg_train_loss: 0.0138  avg_val_loss: 0.0890  val_lwlrap: 0.290803  time: 29s<p>Epoch 311 - avg_train_loss: 0.0149  avg_val_loss: 0.1544  val_lwlrap: 0.134987  time: 29s<p>Epoch 312 - avg_train_loss: 0.0154  avg_val_loss: 0.0919  val_lwlrap: 0.149936  time: 29s<p>Epoch 313 - avg_train_loss: 0.0144  avg_val_loss: 0.1607  val_lwlrap: 0.104431  time: 29s<p>Epoch 314 - avg_train_loss: 0.0143  avg_val_loss: 0.1083  val_lwlrap: 0.295431  time: 29s<p>Epoch 315 - avg_train_loss: 0.0135  avg_val_loss: 0.0825  val_lwlrap: 0.326186  time: 29s<p>Epoch 316 - avg_train_loss: 0.0120  avg_val_loss: 0.0494  val_lwlrap: 0.629721  time: 29s<p>Epoch 317 - avg_train_loss: 0.0122  avg_val_loss: 0.0404  val_lwlrap: 0.657602  time: 29s<p>Epoch 318 - avg_train_loss: 0.0118  avg_val_loss: 0.0459  val_lwlrap: 0.630627  time: 29s<p>Epoch 319 - avg_train_loss: 0.0116  avg_val_loss: 0.0531  val_lwlrap: 0.584864  time: 29s<p>Epoch 320 - avg_train_loss: 0.0121  avg_val_loss: 0.0572  val_lwlrap: 0.553675  time: 29s<p>Epoch 321 - avg_train_loss: 0.0134  avg_val_loss: 0.1008  val_lwlrap: 0.136260  time: 29s<p>Epoch 322 - avg_train_loss: 0.0143  avg_val_loss: 0.0949  val_lwlrap: 0.243256  time: 29s<p>Epoch 323 - avg_train_loss: 0.0135  avg_val_loss: 0.1718  val_lwlrap: 0.123830  time: 29s<p>Epoch 324 - avg_train_loss: 0.0139  avg_val_loss: 0.1551  val_lwlrap: 0.136489  time: 29s<p>Epoch 325 - avg_train_loss: 0.0134  avg_val_loss: 0.0539  val_lwlrap: 0.583727  time: 29s<p>Epoch 326 - avg_train_loss: 0.0116  avg_val_loss: 0.0448  val_lwlrap: 0.653581  time: 29s<p>Epoch 327 - avg_train_loss: 0.0118  avg_val_loss: 0.0404  val_lwlrap: 0.663278  time: 29s<p>Epoch 328 - avg_train_loss: 0.0119  avg_val_loss: 0.0473  val_lwlrap: 0.638239  time: 29s<p>Epoch 329 - avg_train_loss: 0.0121  avg_val_loss: 0.0731  val_lwlrap: 0.496691  time: 29s<p>Epoch 330 - avg_train_loss: 0.0118  avg_val_loss: 0.1466  val_lwlrap: 0.160593  time: 29s<p>Epoch 331 - avg_train_loss: 0.0144  avg_val_loss: 0.1441  val_lwlrap: 0.110698  time: 29s<p>Epoch 332 - avg_train_loss: 0.0138  avg_val_loss: 0.2416  val_lwlrap: 0.087296  time: 29s<p>Epoch 333 - avg_train_loss: 0.0132  avg_val_loss: 0.1578  val_lwlrap: 0.114247  time: 29s<p>Epoch 334 - avg_train_loss: 0.0122  avg_val_loss: 0.1342  val_lwlrap: 0.228252  time: 29s<p>Epoch 335 - avg_train_loss: 0.0123  avg_val_loss: 0.0707  val_lwlrap: 0.426905  time: 29s<p>Epoch 336 - avg_train_loss: 0.0117  avg_val_loss: 0.0499  val_lwlrap: 0.588248  time: 29s<p>Epoch 337 - avg_train_loss: 0.0111  avg_val_loss: 0.0424  val_lwlrap: 0.671517  time: 29s<p>Epoch 338 - avg_train_loss: 0.0104  avg_val_loss: 0.0477  val_lwlrap: 0.609043  time: 29s<p>Epoch 339 - avg_train_loss: 0.0111  avg_val_loss: 0.1122  val_lwlrap: 0.317934  time: 29s<p>Epoch 340 - avg_train_loss: 0.0126  avg_val_loss: 0.0831  val_lwlrap: 0.266938  time: 29s<p>Epoch 341 - avg_train_loss: 0.0143  avg_val_loss: 0.0825  val_lwlrap: 0.265329  time: 29s<p>Epoch 342 - avg_train_loss: 0.0151  avg_val_loss: 0.1615  val_lwlrap: 0.108777  time: 29s<p>Epoch 343 - avg_train_loss: 0.0152  avg_val_loss: 0.2223  val_lwlrap: 0.115283  time: 29s<p>Epoch 344 - avg_train_loss: 0.0137  avg_val_loss: 0.1003  val_lwlrap: 0.249591  time: 29s<p>Epoch 345 - avg_train_loss: 0.0125  avg_val_loss: 0.0652  val_lwlrap: 0.496993  time: 29s<p>Epoch 346 - avg_train_loss: 0.0114  avg_val_loss: 0.0423  val_lwlrap: 0.655762  time: 29s<p>Epoch 347 - avg_train_loss: 0.0112  avg_val_loss: 0.0437  val_lwlrap: 0.664303  time: 29s<p>Epoch 348 - avg_train_loss: 0.0110  avg_val_loss: 0.0441  val_lwlrap: 0.665315  time: 29s<p>Epoch 349 - avg_train_loss: 0.0113  avg_val_loss: 0.0802  val_lwlrap: 0.377404  time: 29s<p>Epoch 350 - avg_train_loss: 0.0123  avg_val_loss: 0.0840  val_lwlrap: 0.348079  time: 29s"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = train_model(x_train, y_train, transforms_dict['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 337, 'best_lwlrap': 0.671517216760171}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(test_fnames, x_test, test_transforms, num_classes, *, tta=5):\n",
    "    batch_size = 256\n",
    "\n",
    "    test_dataset = FATTestDataset(test_fnames, x_test, test_transforms, tta=tta)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = Classifier(num_classes=num_classes)\n",
    "    model.load_state_dict(torch.load('weight_best_4.pt'))\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    all_outputs, all_fnames = [], []\n",
    "\n",
    "    pb = progress_bar(test_loader)\n",
    "    for images, fnames in pb:\n",
    "        preds = torch.sigmoid(model(images.cuda()).detach())\n",
    "        all_outputs.append(preds.cpu().numpy())\n",
    "        all_fnames.extend(fnames)\n",
    "\n",
    "    test_preds = pd.DataFrame(data=np.concatenate(all_outputs),\n",
    "                              index=all_fnames,\n",
    "                              columns=map(str, range(num_classes)))\n",
    "    test_preds = test_preds.groupby(level=0).mean()\n",
    "\n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='88' class='' max='88', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [88/88 00:28<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds = predict_model(test_df['fname'], x_test, transforms_dict['test'], num_classes, tta=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>Accelerating_and_revving_and_vroom</th>\n",
       "      <th>Accordion</th>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <th>Applause</th>\n",
       "      <th>Bark</th>\n",
       "      <th>Bass_drum</th>\n",
       "      <th>Bass_guitar</th>\n",
       "      <th>Bathtub_(filling_or_washing)</th>\n",
       "      <th>Bicycle_bell</th>\n",
       "      <th>Burping_and_eructation</th>\n",
       "      <th>Bus</th>\n",
       "      <th>Buzz</th>\n",
       "      <th>Car_passing_by</th>\n",
       "      <th>Cheering</th>\n",
       "      <th>Chewing_and_mastication</th>\n",
       "      <th>Child_speech_and_kid_speaking</th>\n",
       "      <th>Chink_and_clink</th>\n",
       "      <th>Chirp_and_tweet</th>\n",
       "      <th>Church_bell</th>\n",
       "      <th>Clapping</th>\n",
       "      <th>Computer_keyboard</th>\n",
       "      <th>Crackle</th>\n",
       "      <th>Cricket</th>\n",
       "      <th>Crowd</th>\n",
       "      <th>Cupboard_open_or_close</th>\n",
       "      <th>Cutlery_and_silverware</th>\n",
       "      <th>Dishes_and_pots_and_pans</th>\n",
       "      <th>Drawer_open_or_close</th>\n",
       "      <th>Drip</th>\n",
       "      <th>Electric_guitar</th>\n",
       "      <th>Fart</th>\n",
       "      <th>Female_singing</th>\n",
       "      <th>Female_speech_and_woman_speaking</th>\n",
       "      <th>Fill_(with_liquid)</th>\n",
       "      <th>Finger_snapping</th>\n",
       "      <th>Frying_(food)</th>\n",
       "      <th>Gasp</th>\n",
       "      <th>Glockenspiel</th>\n",
       "      <th>Gong</th>\n",
       "      <th>...</th>\n",
       "      <th>Harmonica</th>\n",
       "      <th>Hi-hat</th>\n",
       "      <th>Hiss</th>\n",
       "      <th>Keys_jangling</th>\n",
       "      <th>Knock</th>\n",
       "      <th>Male_singing</th>\n",
       "      <th>Male_speech_and_man_speaking</th>\n",
       "      <th>Marimba_and_xylophone</th>\n",
       "      <th>Mechanical_fan</th>\n",
       "      <th>Meow</th>\n",
       "      <th>Microwave_oven</th>\n",
       "      <th>Motorcycle</th>\n",
       "      <th>Printer</th>\n",
       "      <th>Purr</th>\n",
       "      <th>Race_car_and_auto_racing</th>\n",
       "      <th>Raindrop</th>\n",
       "      <th>Run</th>\n",
       "      <th>Scissors</th>\n",
       "      <th>Screaming</th>\n",
       "      <th>Shatter</th>\n",
       "      <th>Sigh</th>\n",
       "      <th>Sink_(filling_or_washing)</th>\n",
       "      <th>Skateboard</th>\n",
       "      <th>Slam</th>\n",
       "      <th>Sneeze</th>\n",
       "      <th>Squeak</th>\n",
       "      <th>Stream</th>\n",
       "      <th>Strum</th>\n",
       "      <th>Tap</th>\n",
       "      <th>Tick-tock</th>\n",
       "      <th>Toilet_flush</th>\n",
       "      <th>Traffic_noise_and_roadway_noise</th>\n",
       "      <th>Trickle_and_dribble</th>\n",
       "      <th>Walk_and_footsteps</th>\n",
       "      <th>Water_tap_and_faucet</th>\n",
       "      <th>Waves_and_surf</th>\n",
       "      <th>Whispering</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Yell</th>\n",
       "      <th>Zipper_(clothing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000ccb97.wav</td>\n",
       "      <td>2.235729e-08</td>\n",
       "      <td>8.401939e-11</td>\n",
       "      <td>8.733840e-07</td>\n",
       "      <td>7.686482e-09</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>1.774915e-06</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>3.505699e-05</td>\n",
       "      <td>3.324989e-07</td>\n",
       "      <td>1.868862e-05</td>\n",
       "      <td>6.202818e-09</td>\n",
       "      <td>6.935662e-05</td>\n",
       "      <td>1.299574e-08</td>\n",
       "      <td>1.340522e-10</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>1.127060e-06</td>\n",
       "      <td>2.691214e-06</td>\n",
       "      <td>7.101187e-05</td>\n",
       "      <td>6.482882e-07</td>\n",
       "      <td>2.664094e-06</td>\n",
       "      <td>4.824316e-05</td>\n",
       "      <td>4.067556e-04</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>4.387792e-10</td>\n",
       "      <td>6.621741e-06</td>\n",
       "      <td>6.297324e-03</td>\n",
       "      <td>1.262232e-04</td>\n",
       "      <td>4.777561e-06</td>\n",
       "      <td>8.289407e-05</td>\n",
       "      <td>3.988047e-09</td>\n",
       "      <td>1.515729e-05</td>\n",
       "      <td>9.057388e-07</td>\n",
       "      <td>4.869840e-05</td>\n",
       "      <td>4.347434e-07</td>\n",
       "      <td>1.175548e-01</td>\n",
       "      <td>3.841305e-04</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>6.006740e-07</td>\n",
       "      <td>2.488599e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.078148e-06</td>\n",
       "      <td>1.125715e-01</td>\n",
       "      <td>0.042959</td>\n",
       "      <td>2.536049e-02</td>\n",
       "      <td>2.808220e-07</td>\n",
       "      <td>6.932116e-07</td>\n",
       "      <td>6.152765e-08</td>\n",
       "      <td>1.295568e-09</td>\n",
       "      <td>1.773524e-05</td>\n",
       "      <td>1.817788e-08</td>\n",
       "      <td>9.520146e-08</td>\n",
       "      <td>1.476383e-06</td>\n",
       "      <td>4.637868e-06</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.617885e-09</td>\n",
       "      <td>4.056582e-05</td>\n",
       "      <td>1.477081e-06</td>\n",
       "      <td>7.602338e-02</td>\n",
       "      <td>1.010195e-07</td>\n",
       "      <td>1.390588e-02</td>\n",
       "      <td>8.235318e-06</td>\n",
       "      <td>6.010243e-06</td>\n",
       "      <td>2.926203e-07</td>\n",
       "      <td>4.818444e-09</td>\n",
       "      <td>1.945807e-05</td>\n",
       "      <td>4.170817e-06</td>\n",
       "      <td>1.282306e-08</td>\n",
       "      <td>1.461656e-06</td>\n",
       "      <td>2.729984e-07</td>\n",
       "      <td>1.049964e-04</td>\n",
       "      <td>1.219384e-04</td>\n",
       "      <td>1.174155e-09</td>\n",
       "      <td>4.854788e-08</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>4.869285e-05</td>\n",
       "      <td>3.768471e-07</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>1.032013e-03</td>\n",
       "      <td>1.472690e-08</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0012633b.wav</td>\n",
       "      <td>2.256532e-01</td>\n",
       "      <td>3.719034e-04</td>\n",
       "      <td>5.279218e-04</td>\n",
       "      <td>2.551619e-03</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>3.417646e-04</td>\n",
       "      <td>0.022291</td>\n",
       "      <td>1.171682e-04</td>\n",
       "      <td>1.528345e-03</td>\n",
       "      <td>8.126194e-04</td>\n",
       "      <td>2.668324e-03</td>\n",
       "      <td>1.730575e-02</td>\n",
       "      <td>1.683973e-03</td>\n",
       "      <td>5.283367e-04</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>3.303064e-04</td>\n",
       "      <td>7.130228e-04</td>\n",
       "      <td>1.106055e-03</td>\n",
       "      <td>4.683577e-03</td>\n",
       "      <td>2.614815e-04</td>\n",
       "      <td>1.224980e-03</td>\n",
       "      <td>2.322046e-03</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>5.326015e-03</td>\n",
       "      <td>3.061546e-03</td>\n",
       "      <td>2.480836e-03</td>\n",
       "      <td>1.232738e-04</td>\n",
       "      <td>1.908744e-02</td>\n",
       "      <td>2.148417e-05</td>\n",
       "      <td>2.984297e-03</td>\n",
       "      <td>9.569168e-03</td>\n",
       "      <td>1.669880e-03</td>\n",
       "      <td>3.941054e-03</td>\n",
       "      <td>7.518983e-05</td>\n",
       "      <td>1.516049e-04</td>\n",
       "      <td>5.141420e-04</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>1.281856e-03</td>\n",
       "      <td>1.119479e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>6.974537e-03</td>\n",
       "      <td>3.485444e-03</td>\n",
       "      <td>0.017459</td>\n",
       "      <td>2.300120e-03</td>\n",
       "      <td>5.987718e-04</td>\n",
       "      <td>1.348385e-02</td>\n",
       "      <td>4.243692e-03</td>\n",
       "      <td>5.691599e-05</td>\n",
       "      <td>1.408673e-03</td>\n",
       "      <td>3.037444e-04</td>\n",
       "      <td>1.186931e-03</td>\n",
       "      <td>4.743364e-01</td>\n",
       "      <td>2.100146e-03</td>\n",
       "      <td>0.005163</td>\n",
       "      <td>9.797123e-03</td>\n",
       "      <td>3.991079e-05</td>\n",
       "      <td>4.304660e-03</td>\n",
       "      <td>1.562132e-03</td>\n",
       "      <td>4.141726e-04</td>\n",
       "      <td>1.846187e-01</td>\n",
       "      <td>4.561762e-02</td>\n",
       "      <td>8.222936e-04</td>\n",
       "      <td>7.092436e-04</td>\n",
       "      <td>5.016387e-03</td>\n",
       "      <td>1.833053e-03</td>\n",
       "      <td>1.530781e-02</td>\n",
       "      <td>1.472640e-04</td>\n",
       "      <td>7.288228e-04</td>\n",
       "      <td>1.268654e-04</td>\n",
       "      <td>7.988464e-05</td>\n",
       "      <td>2.042423e-03</td>\n",
       "      <td>4.633504e-03</td>\n",
       "      <td>3.994475e-05</td>\n",
       "      <td>0.058793</td>\n",
       "      <td>1.888209e-04</td>\n",
       "      <td>1.505908e-03</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>1.055821e-03</td>\n",
       "      <td>1.906289e-03</td>\n",
       "      <td>0.085272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ed5f1.wav</td>\n",
       "      <td>1.440226e-04</td>\n",
       "      <td>8.929374e-05</td>\n",
       "      <td>4.913432e-05</td>\n",
       "      <td>7.023186e-04</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>2.912716e-03</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>4.610915e-04</td>\n",
       "      <td>1.173409e-04</td>\n",
       "      <td>5.694867e-04</td>\n",
       "      <td>1.758882e-03</td>\n",
       "      <td>4.421865e-04</td>\n",
       "      <td>1.741422e-04</td>\n",
       "      <td>5.211070e-04</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>1.020149e-04</td>\n",
       "      <td>7.828448e-04</td>\n",
       "      <td>3.930485e-04</td>\n",
       "      <td>6.027341e-05</td>\n",
       "      <td>1.736577e-03</td>\n",
       "      <td>1.516085e-02</td>\n",
       "      <td>3.545148e-03</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>6.923431e-04</td>\n",
       "      <td>1.260443e-01</td>\n",
       "      <td>1.225719e-04</td>\n",
       "      <td>1.375061e-02</td>\n",
       "      <td>1.037178e-02</td>\n",
       "      <td>2.490290e-04</td>\n",
       "      <td>1.731760e-03</td>\n",
       "      <td>1.331954e-03</td>\n",
       "      <td>1.402426e-04</td>\n",
       "      <td>3.254985e-04</td>\n",
       "      <td>7.974151e-05</td>\n",
       "      <td>6.101905e-04</td>\n",
       "      <td>6.400960e-05</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>4.591055e-05</td>\n",
       "      <td>1.016325e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.013023e-04</td>\n",
       "      <td>3.914637e-03</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>3.618066e-04</td>\n",
       "      <td>3.761900e-02</td>\n",
       "      <td>6.334324e-04</td>\n",
       "      <td>2.073382e-03</td>\n",
       "      <td>1.839210e-05</td>\n",
       "      <td>6.257953e-04</td>\n",
       "      <td>4.998058e-04</td>\n",
       "      <td>1.554096e-02</td>\n",
       "      <td>1.760560e-04</td>\n",
       "      <td>1.962047e-02</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>1.642483e-05</td>\n",
       "      <td>3.465752e-04</td>\n",
       "      <td>6.155412e-01</td>\n",
       "      <td>4.375930e-04</td>\n",
       "      <td>7.382633e-04</td>\n",
       "      <td>9.691012e-04</td>\n",
       "      <td>6.873449e-05</td>\n",
       "      <td>2.149381e-04</td>\n",
       "      <td>8.135143e-05</td>\n",
       "      <td>1.978587e-02</td>\n",
       "      <td>1.075483e-04</td>\n",
       "      <td>8.953385e-03</td>\n",
       "      <td>1.526733e-05</td>\n",
       "      <td>1.712800e-05</td>\n",
       "      <td>7.713654e-02</td>\n",
       "      <td>5.412945e-04</td>\n",
       "      <td>7.058683e-05</td>\n",
       "      <td>1.070584e-04</td>\n",
       "      <td>1.486673e-06</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>1.300537e-05</td>\n",
       "      <td>3.727008e-05</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>2.240041e-03</td>\n",
       "      <td>5.135244e-04</td>\n",
       "      <td>0.000887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00294be0.wav</td>\n",
       "      <td>1.990984e-08</td>\n",
       "      <td>1.993855e-07</td>\n",
       "      <td>1.704940e-08</td>\n",
       "      <td>3.846779e-11</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.234756e-09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.098770e-10</td>\n",
       "      <td>2.016270e-08</td>\n",
       "      <td>4.156214e-08</td>\n",
       "      <td>1.104133e-08</td>\n",
       "      <td>1.885578e-09</td>\n",
       "      <td>1.302325e-04</td>\n",
       "      <td>8.203875e-14</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.611653e-08</td>\n",
       "      <td>2.016580e-08</td>\n",
       "      <td>1.951638e-08</td>\n",
       "      <td>1.188688e-07</td>\n",
       "      <td>2.271594e-14</td>\n",
       "      <td>1.722564e-09</td>\n",
       "      <td>6.183595e-08</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>6.379421e-10</td>\n",
       "      <td>1.413423e-11</td>\n",
       "      <td>3.490215e-14</td>\n",
       "      <td>8.078382e-17</td>\n",
       "      <td>5.242779e-09</td>\n",
       "      <td>7.316850e-11</td>\n",
       "      <td>5.212388e-12</td>\n",
       "      <td>2.902835e-07</td>\n",
       "      <td>9.880240e-05</td>\n",
       "      <td>7.184939e-10</td>\n",
       "      <td>7.421414e-07</td>\n",
       "      <td>5.391994e-10</td>\n",
       "      <td>7.526375e-11</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.779995e-08</td>\n",
       "      <td>2.136280e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>2.768930e-10</td>\n",
       "      <td>3.198585e-17</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>3.212445e-08</td>\n",
       "      <td>2.861314e-07</td>\n",
       "      <td>7.247242e-11</td>\n",
       "      <td>4.739414e-07</td>\n",
       "      <td>3.712847e-12</td>\n",
       "      <td>6.018996e-11</td>\n",
       "      <td>2.089421e-02</td>\n",
       "      <td>4.457763e-13</td>\n",
       "      <td>3.082266e-07</td>\n",
       "      <td>3.763235e-12</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>7.441265e-10</td>\n",
       "      <td>8.167319e-10</td>\n",
       "      <td>1.953856e-08</td>\n",
       "      <td>6.503827e-11</td>\n",
       "      <td>1.888676e-09</td>\n",
       "      <td>4.977948e-12</td>\n",
       "      <td>3.969474e-08</td>\n",
       "      <td>7.462301e-08</td>\n",
       "      <td>3.829065e-13</td>\n",
       "      <td>2.993307e-07</td>\n",
       "      <td>1.552380e-10</td>\n",
       "      <td>4.846918e-10</td>\n",
       "      <td>4.247388e-07</td>\n",
       "      <td>1.886121e-08</td>\n",
       "      <td>5.649297e-09</td>\n",
       "      <td>8.083372e-08</td>\n",
       "      <td>1.229425e-10</td>\n",
       "      <td>5.601338e-11</td>\n",
       "      <td>7.068787e-07</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>4.850339e-09</td>\n",
       "      <td>1.114338e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.774389e-09</td>\n",
       "      <td>2.675214e-09</td>\n",
       "      <td>0.002148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003fde7a.wav</td>\n",
       "      <td>4.405760e-06</td>\n",
       "      <td>3.643788e-05</td>\n",
       "      <td>1.819244e-05</td>\n",
       "      <td>2.719564e-06</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>7.734648e-05</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>9.225401e-06</td>\n",
       "      <td>8.139606e-01</td>\n",
       "      <td>2.378017e-04</td>\n",
       "      <td>1.047352e-04</td>\n",
       "      <td>6.502954e-05</td>\n",
       "      <td>3.467561e-06</td>\n",
       "      <td>1.019697e-06</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>1.973713e-05</td>\n",
       "      <td>5.398582e-04</td>\n",
       "      <td>1.436683e-05</td>\n",
       "      <td>3.323050e-06</td>\n",
       "      <td>9.881107e-07</td>\n",
       "      <td>1.450296e-03</td>\n",
       "      <td>1.755350e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>5.799786e-07</td>\n",
       "      <td>1.079698e-06</td>\n",
       "      <td>8.357590e-04</td>\n",
       "      <td>5.576527e-05</td>\n",
       "      <td>8.769088e-03</td>\n",
       "      <td>5.721128e-04</td>\n",
       "      <td>4.722386e-07</td>\n",
       "      <td>8.842874e-05</td>\n",
       "      <td>3.569448e-06</td>\n",
       "      <td>1.820505e-06</td>\n",
       "      <td>1.001506e-05</td>\n",
       "      <td>3.979203e-04</td>\n",
       "      <td>3.992332e-05</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>1.819766e-01</td>\n",
       "      <td>3.332247e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.776234e-04</td>\n",
       "      <td>6.562022e-06</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>9.906143e-06</td>\n",
       "      <td>1.311810e-05</td>\n",
       "      <td>8.031266e-06</td>\n",
       "      <td>7.087077e-07</td>\n",
       "      <td>3.619417e-03</td>\n",
       "      <td>4.851809e-05</td>\n",
       "      <td>1.202841e-05</td>\n",
       "      <td>2.256559e-04</td>\n",
       "      <td>9.433171e-06</td>\n",
       "      <td>4.798112e-05</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>2.478341e-05</td>\n",
       "      <td>5.228665e-05</td>\n",
       "      <td>1.667787e-05</td>\n",
       "      <td>1.202738e-05</td>\n",
       "      <td>4.788021e-05</td>\n",
       "      <td>3.773098e-04</td>\n",
       "      <td>3.727151e-05</td>\n",
       "      <td>2.547647e-04</td>\n",
       "      <td>1.583446e-06</td>\n",
       "      <td>1.024904e-05</td>\n",
       "      <td>3.827423e-05</td>\n",
       "      <td>4.527697e-05</td>\n",
       "      <td>4.876774e-07</td>\n",
       "      <td>2.004041e-05</td>\n",
       "      <td>1.235360e-04</td>\n",
       "      <td>2.609530e-05</td>\n",
       "      <td>2.319520e-06</td>\n",
       "      <td>2.649020e-06</td>\n",
       "      <td>1.698947e-07</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>3.106644e-05</td>\n",
       "      <td>1.696113e-05</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>2.634647e-06</td>\n",
       "      <td>1.014172e-06</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname        ...          Zipper_(clothing)\n",
       "0  000ccb97.wav        ...                   0.000004\n",
       "1  0012633b.wav        ...                   0.085272\n",
       "2  001ed5f1.wav        ...                   0.000887\n",
       "3  00294be0.wav        ...                   0.002148\n",
       "4  003fde7a.wav        ...                   0.000024\n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[labels] = test_preds.values\n",
    "test_df.to_csv('submission.csv', index=False)\n",
    "test_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
