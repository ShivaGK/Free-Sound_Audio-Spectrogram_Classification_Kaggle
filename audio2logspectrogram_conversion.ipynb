{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.utils import shuffle # shuffling of data\n",
    "from random import sample # random selection\n",
    "from tqdm import tqdm # progress bar\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "from PIL import Image\n",
    "import h5py\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_specgram(audio, sample_rate, window_size=10, \n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    _, _, spec = signal.spectrogram(audio, fs=sample_rate,\n",
    "                                    window='hann', nperseg=nperseg, noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return np.log(spec.T.astype(np.float32) + eps)\n",
    "\n",
    "def audio_to_data(filepath1):\n",
    "    # we take a single path and convert it into data\n",
    "    sample_rate, audio = wavfile.read(filepath1)\n",
    "    spectrogram = log_specgram(audio, sample_rate, 10, 0)\n",
    "    return spectrogram.T\n",
    "\n",
    "def paths_to_data(paths):\n",
    "    data = []\n",
    "    #labels = []\n",
    "    for i in tqdm(range(len(paths))):\n",
    "        f = paths[i]\n",
    "        audio = audio_to_data(path + paths[i])        \n",
    "        data[i] = audio\n",
    "        #labels.append(word2id[f.split('/')[-2]])\n",
    "    return data, labels\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_curated_annot = pd.read_csv('../input/train_curated.csv')\n",
    "train_curated_path = '../input/train_curated/'\n",
    "train_curated_files = os.listdir(train_curated_path)\n",
    "path = train_curated_path\n",
    "\n",
    "imgw, imgh  = 128, 128\n",
    "data2 = np.zeros(shape = (len(train_curated_files), imgw, imgh))\n",
    "                 \n",
    "for i in range(len(train_curated_files)):\n",
    "    data1= audio_to_data(path + train_curated_files[i])\n",
    "    img=Image.fromarray(data1)\n",
    "    img = img.resize((imgw, imgh), Image.ANTIALIAS)\n",
    "    data2[i]=np.array(img)\n",
    "\n",
    "h5f = h5py.File('data_img_traincurate.h5', 'w')\n",
    "h5f.create_dataset('train_curated_hdf', data=data2)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_noisy_annot = pd.read_csv('../input/train_noisy.csv')\n",
    "train_noisy_audio_path = '../input/train_noisy/'\n",
    "train_noisy_files = os.listdir(train_noisy_audio_path)\n",
    "path = train_noisy_audio_path\n",
    "\n",
    "imgw, imgh  = 128, 128\n",
    "data2 = np.zeros(shape = (len(train_noisy_files), imgw, imgh))\n",
    "                 \n",
    "for i in range(len(train_noisy_files)):\n",
    "    data1= audio_to_data(path + train_noisy_files[i])\n",
    "    img=Image.fromarray(data1)\n",
    "    img = img.resize((imgw, imgh), Image.ANTIALIAS)\n",
    "    data2[i]=np.array(img)\n",
    "\n",
    "h5f = h5py.File('data_img_trainnoisy.h5', 'w')\n",
    "h5f.create_dataset('train_noisy_hdf', data=data2)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio_path = '../input/test/'\n",
    "test_files = np.sort(os.listdir(test_audio_path))\n",
    "path = test_audio_path\n",
    "\n",
    "imgw, imgh  = 128, 128\n",
    "data2 = np.zeros(shape = (len(test_files), imgw, imgh))\n",
    "                 \n",
    "for i in range(len(test_files)):\n",
    "    data1= audio_to_data(path + test_files[i])\n",
    "    img=Image.fromarray(data1)\n",
    "    img = img.resize((imgw, imgh), Image.ANTIALIAS)\n",
    "    data2[i]=np.array(img)\n",
    "\n",
    "h5f = h5py.File('data_img_test.h5', 'w')\n",
    "h5f.create_dataset('test_hdf', data=data2)\n",
    "h5f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
